{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import skimage\n",
    "from skimage import io\n",
    "from skimage import img_as_float\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from os import listdir\n",
    "from skimage import io, transform, util, img_as_float\n",
    "from tqdm import tqdm_notebook\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from PIL import Image\n",
    "from fastnumbers import fast_real\n",
    "from keras import Sequential\n",
    "from keras import models\n",
    "from keras.layers.core import Activation, Reshape, Permute\n",
    "from keras.layers import Conv2D, Flatten, Dropout, Dense, MaxPooling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt2mask (path):\n",
    "    yLinesCoords = []\n",
    "    f = open(path, 'r', encoding='utf-16')\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        line = f.readline()\n",
    "        if line.split(\"\t\")[0] != \"\" :\n",
    "            num1 = line.split(\"\t\")[0]\n",
    "            num2 = line.split(\"\t\")[1].split(\"\\n\")[0]\n",
    "            yLinesCoords.append(fast_real(num1))\n",
    "            yLinesCoords.append(fast_real(num2))\n",
    "    f.close()\n",
    "    \n",
    "    res = np.zeros((h, w))\n",
    "    i = 0\n",
    "    while i < len(yLinesCoords)/2:\n",
    "        j = yLinesCoords[2*i]\n",
    "        while j < yLinesCoords[2*i + 1]:\n",
    "            for k in range(w):\n",
    "                res[j][k] = 1\n",
    "            j += 1\n",
    "        i += 1   \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape32 (img):\n",
    "    padded_img = np.zeros((3520, 2496))\n",
    "    padded_img[:img.shape[0], :img.shape[1]] = img\n",
    "    return padded_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_samples = 100\n",
    "n_test_samples = 20\n",
    "n_labels = 2\n",
    "kernel = 15\n",
    "h = 3520 #3508\n",
    "w = 2496 #2480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:08,  2.82s/it]/home/ivan/anaconda3/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "80it [03:38,  2.73s/it]\n"
     ]
    }
   ],
   "source": [
    "#_train\n",
    "#X_train = np.zeros((n_train_samples, h, w))\n",
    "#Y_train = np.zeros((n_train_samples, h, w))\n",
    "\n",
    "for i, filename in tqdm(enumerate(os.listdir('train_img/')[:n_train_samples])):\n",
    "    onlyName = filename.split('.')[0]\n",
    "    img = skimage.io.imread('train_img/' + filename)\n",
    "    if img.shape != (3508, 2480):\n",
    "        raise ValueError('yobik')\n",
    "    shaped = shape32(img)\n",
    "    normalized = shaped / 255.0\n",
    "    x_arr = normalized\n",
    "    y_arr = txt2mask('train_txt/' + onlyName + '.txt')\n",
    "    np.savez_compressed('saved/train/' + onlyName + '.npz', x=x_arr, y=y_arr)\n",
    "    #X_train[i] = normalized\n",
    "    #Y_train[i] = txt2mask('train_txt/' + filename.split('.')[0] + '.txt')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:08,  2.83s/it]/home/ivan/anaconda3/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "20it [00:56,  2.82s/it]\n"
     ]
    }
   ],
   "source": [
    "#_test\n",
    "#X_test = np.zeros((n_test_samples, h, w))\n",
    "#Y_test = np.zeros((n_test_samples, h, w))\n",
    "\n",
    "for i, filename in tqdm(enumerate(os.listdir('test_img/')[:n_test_samples])):\n",
    "    img = skimage.io.imread('test_img/' + filename)\n",
    "    if img.shape != (3508, 2480):\n",
    "        raise ValueError('yobik')\n",
    "    shaped = shape32(img)\n",
    "    normalized = shaped / 255.0\n",
    "    x_arr = normalized\n",
    "    y_arr = txt2mask('test_txt/' + filename.split('.')[0] + '.txt')\n",
    "    np.savez_compressed('saved/test/' + filename.split('.')[0] + '.npz', x=x_arr, y=y_arr)\n",
    "    #X_test[i] = normalized\n",
    "    #Y_test[i] = txt2mask('test_txt/' + filename.split('.')[0] + '.txt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('saved/arrays_train.npz', xtrain=X_train, ytrain = Y_train)\n",
    "np.savez_compressed('saved/arrays_test.npz', xtest=X_test, ytest = Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_generator(directory, batch_size):\n",
    "    filenames = os.listdir(directory)\n",
    "    while True:\n",
    "        n_iter = len(filenames) // batch_size\n",
    "        residual = len(filenames) % batch_size\n",
    "        for i in range(n_iter):\n",
    "            size = batch_size\n",
    "            if (i == n_iter - 1) and (residual > 0):\n",
    "                size = residual\n",
    "            X = np.zeros((batch_size, h, w, 1))\n",
    "            y = np.zeros((batch_size, h * w))\n",
    "            for j in range(size):\n",
    "                X[j] = np.load(directory + filenames[i * batch_size + j])['x'].reshape((h, w, 1))\n",
    "                y = np.load(directory + filenames[i * batch_size + j])['y'].reshape((h * w, ))\n",
    "                y[j] = \n",
    "            yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = img_generator('saved/train/', 5)\n",
    "test_generator = img_generator('saved/test/', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_train = np.load('saved/arrays_train.npz')\n",
    "loaded_test = np.load('saved/arrays_test.npz')\n",
    "X_train = loaded_train['xtrain']\n",
    "Y_train = loaded_train['ytrain']\n",
    "X_test = loaded_test['xtest']\n",
    "Y_test = loaded_test['ytest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (15, 15), input_shape=(3520, 249..., padding=\"same\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (15, 15), padding=\"same\")`\n",
      "  \n",
      "/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (15, 15), padding=\"same\")`\n",
      "  del sys.path[0]\n",
      "/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (15, 15), padding=\"same\")`\n",
      "/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (15, 15), padding=\"same\")`\n",
      "/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (15, 15), padding=\"same\")`\n",
      "/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (15, 15), padding=\"same\")`\n",
      "/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:46: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (15, 15), padding=\"same\")`\n",
      "/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:51: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (15, 15), padding=\"same\")`\n",
      "/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (15, 15), padding=\"same\")`\n",
      "/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:61: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (15, 15), padding=\"same\")`\n",
      "/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:66: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (15, 15), padding=\"same\")`\n",
      "/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:69: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2, (1, 1), padding=\"valid\")`\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Sequential()\n",
    "encoding_layers = [\n",
    "    Convolution2D(16, kernel, kernel, border_mode='same', input_shape=( 3520, 2496, 1)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(),\n",
    "#    \n",
    "    Convolution2D(32, kernel, kernel, border_mode='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(),\n",
    "#    \n",
    "    Convolution2D(32, kernel, kernel, border_mode='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(),\n",
    "#\n",
    "    Convolution2D(64, kernel, kernel, border_mode='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "#   \n",
    "    Convolution2D(64, kernel, kernel, border_mode='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(),\n",
    "#    \n",
    "    Convolution2D(64, kernel, kernel, border_mode='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(),\n",
    "]\n",
    "\n",
    "\n",
    "for l in encoding_layers:\n",
    "    autoencoder.add(l)\n",
    "    #print(l.input_shape,l.output_shape,l)\n",
    "\n",
    "decoding_layers = [\n",
    "    UpSampling2D(),\n",
    "    Convolution2D(64, kernel, kernel, border_mode='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    \n",
    "#   \n",
    "    UpSampling2D(),\n",
    "    Convolution2D(64, kernel, kernel, border_mode='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    \n",
    "#   \n",
    "    Convolution2D(64, kernel, kernel, border_mode='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "#\n",
    "    UpSampling2D(),\n",
    "    Convolution2D(32, kernel, kernel, border_mode='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "#   \n",
    "    UpSampling2D(),\n",
    "    Convolution2D(32, kernel, kernel, border_mode='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "#\n",
    "    UpSampling2D(),\n",
    "    Convolution2D(16, kernel, kernel, border_mode='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Convolution2D(n_labels, 1, 1, border_mode='valid'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "]\n",
    "\n",
    "for l in decoding_layers:\n",
    "    autoencoder.add(l)\n",
    "    #print(l.input_shape,l.output_shape,l)\n",
    "autoencoder.add(Reshape((n_labels, 3520 * 2496)))\n",
    "autoencoder.add(Permute((2, 1)))\n",
    "autoencoder.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 3520, 2496, 16)    3616      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 3520, 2496, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 3520, 2496, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 1760, 1248, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 1760, 1248, 32)    115232    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 1760, 1248, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 1760, 1248, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 880, 624, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 880, 624, 32)      230432    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 880, 624, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 880, 624, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 440, 312, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 440, 312, 64)      460864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 440, 312, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 440, 312, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 440, 312, 64)      921664    \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 440, 312, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 440, 312, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 220, 156, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 220, 156, 64)      921664    \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 220, 156, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 220, 156, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 110, 78, 64)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2 (None, 220, 156, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 220, 156, 64)      921664    \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 220, 156, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 220, 156, 64)      0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2 (None, 440, 312, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 440, 312, 64)      921664    \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 440, 312, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 440, 312, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 440, 312, 64)      921664    \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 440, 312, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 440, 312, 64)      0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2 (None, 880, 624, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 880, 624, 32)      460832    \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 880, 624, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 880, 624, 32)      0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2 (None, 1760, 1248, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 1760, 1248, 32)    230432    \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 1760, 1248, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 1760, 1248, 32)    0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling (None, 3520, 2496, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 3520, 2496, 16)    115216    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 3520, 2496, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 3520, 2496, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 3520, 2496, 2)     34        \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 3520, 2496, 2)     8         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 2, 8785920)        0         \n",
      "_________________________________________________________________\n",
      "permute_2 (Permute)          (None, 8785920, 2)        0         \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 8785920, 2)        0         \n",
      "=================================================================\n",
      "Total params: 6,227,162\n",
      "Trainable params: 6,226,070\n",
      "Non-trainable params: 1,092\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected activation_32 to have shape (8785920, 2) but got array with shape (3520, 2496)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-7d2e416e0480>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1313\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1875\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1877\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1878\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected activation_32 to have shape (8785920, 2) but got array with shape (3520, 2496)"
     ]
    }
   ],
   "source": [
    "train_generator = img_generator('saved/train/', 5)\n",
    "test_generator = img_generator('saved/test/', 5)\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "autoencoder.fit_generator(train_generator, steps_per_epoch=100//5, epochs=10, validation_data=test_generator, validation_steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLinesFromFile (path):\n",
    "    data = []\n",
    "    f = open(path, 'r', encoding='utf-16')\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        line = f.readline()\n",
    "        if line.split(\"\t\")[0] != \"\" :\n",
    "            num1 = line.split(\"\t\")[0]\n",
    "            num2 = line.split(\"\t\")[1].split(\"\\n\")[0]\n",
    "            data.append(fast_real(num1))\n",
    "            data.append(fast_real(num2))\n",
    "    f.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTextAndBackAreas (yLinesCoords):\n",
    "    res = np.zeros(3508)\n",
    "    i = 0\n",
    "    while i < len(yLinesCoords)/2:\n",
    "        j = yLinesCoords[2*i]\n",
    "        while j < yLinesCoords[2*i + 1]:\n",
    "            res[j] = 1\n",
    "            j += 1\n",
    "        i += 1   \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertJpg2Png (path):\n",
    "    im = Image.open(path)\n",
    "    im.save(path.split('.')[0] + '.png')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2greyscale (path):\n",
    "    img = Image.open(path).convert('LA')\n",
    "    img.save(path.split('.')[0] + '_greyscale.png')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizePng (path, newWidth, newHeigth):\n",
    "    img = Image.open(path)\n",
    "    resized_img = img.resize((newWidth, newHeigth), Image.ANTIALIAS)\n",
    "    resized_img.save(path.split('.')[0] + '_resized.png')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregate2array (path, width, heigth):\n",
    "    img = Image.open(path)\n",
    "    pix = np.array(img)\n",
    "    res = []\n",
    "    for i in range(heigth):\n",
    "        greySum = 0\n",
    "        for j in range(width):\n",
    "            greySum += pix[i][j][0]/pix[i][j][1]\n",
    "        greyAverage = greySum/width\n",
    "        res.append(greyAverage)\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_lines = \"582.txt\"\n",
    "path_to_img = \"582.jpg\"\n",
    "width = 2480\n",
    "heigth = 3508"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yLinesCoords = getLinesFromFile (path_to_lines)\n",
    "oneZeroArr = getTextAndBackAreas(yLinesCoords)\n",
    "\n",
    "convertJpg2Png (path_to_img)\n",
    "convert2greyscale (path_to_img)\n",
    "greyAgrArr = agregate2array (path_to_img.split('.')[0] + '_greyscale.png', width, heigth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (oneZeroArr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (greyAgrArr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneZeroArr = oneZeroArr.reshape (1, -1)\n",
    "greyAgrArr = greyAgrArr.reshape (1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (oneZeroArr.shape)\n",
    "print (greyAgrArr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_img2 = \"583.jpg\"\n",
    "convertJpg2Png (path_to_img2)\n",
    "convert2greyscale (path_to_img2)\n",
    "greyAgrArr2 = agregate2array (path_to_img2.split('.')[0] + '_greyscale.png', width, heigth)\n",
    "greyAgrArr2 = greyAgrArr2.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, Activation\n",
    "\n",
    "max_features = 1000\n",
    "maxlen = 3508 \n",
    "batch_size = 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 3508, input_length=maxlen))\n",
    "model.add(LSTM(3508))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam'\n",
    "              )\n",
    "\n",
    "model.fit(\n",
    "    greyAgrArr, oneZeroArr, \n",
    "    batch_size=batch_size, \n",
    "    nb_epoch=1,\n",
    "    verbose = 1,\n",
    "    \n",
    ")\n",
    "\n",
    "result = model.predict_proba(greyAgrArr2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = model.predict_proba(greyAgrArr2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yLinesCoords2 = getLinesFromFile ('583.txt')\n",
    "oneZeroArr2 = getTextAndBackAreas(yLinesCoords2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(oneZeroArr2, result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(result[0] > 0.5, oneZeroArr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"saved_best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
